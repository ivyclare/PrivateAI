{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS211: Data Privacy\n",
    "## Homework 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def gaussian_mech(v, sensitivity, epsilon, delta):\n",
    "    return v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "\n",
    "def gaussian_mech_vec(vec, sensitivity, epsilon, delta):\n",
    "    return [v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "            for v in vec]\n",
    "\n",
    "def pct_error(orig, priv):\n",
    "    return np.abs(orig - priv)/orig * 100.0\n",
    "\n",
    "# adult = pd.read_csv('https://github.com/jnear/cs211-data-privacy/raw/master/homework/adult_with_pii.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data files\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import io\n",
    "\n",
    "url_x = 'https://github.com/jnear/cs211-data-privacy/raw/master/slides/adult_processed_x.npy'\n",
    "url_y = 'https://github.com/jnear/cs211-data-privacy/raw/master/slides/adult_processed_y.npy'\n",
    "\n",
    "with urllib.request.urlopen(url_x) as url:\n",
    "    f = io.BytesIO(url.read())\n",
    "X = np.load(f)\n",
    "\n",
    "with urllib.request.urlopen(url_y) as url:\n",
    "    f = io.BytesIO(url.read())\n",
    "y = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test set sizes: 36176 9044\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "training_size = int(X.shape[0] * 0.8)\n",
    "\n",
    "X_train = X[:training_size]\n",
    "X_test = X[training_size:]\n",
    "\n",
    "y_train = y[:training_size]\n",
    "y_test = y[training_size:]\n",
    "\n",
    "print('Train and test set sizes:', len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss function measures how good our model is. The training goal is to minimize the loss.\n",
    "# This is the logistic loss function.\n",
    "def loss(theta, xi, yi):\n",
    "    exponent = - yi * (xi.dot(theta))\n",
    "    return np.log(1 + np.exp(exponent))\n",
    "\n",
    "# This is the gradient of the logistic loss\n",
    "# The gradient is a vector that indicates the rate of change of the loss in each direction\n",
    "def gradient(theta, xi, yi):\n",
    "    exponent = yi * (xi.dot(theta))\n",
    "    return - (yi*xi) / (1+np.exp(exponent))\n",
    "\n",
    "def avg_grad(theta, X, y):\n",
    "    grads = [gradient(theta, xi, yi) for xi, yi in zip(X, y)]\n",
    "    return np.mean(grads, axis=0)\n",
    "\n",
    "# Prediction: take a model (theta) and a single example (xi) and return its predicted label\n",
    "def predict(xi, theta, bias=0):\n",
    "    label = np.sign(xi @ theta + bias)\n",
    "    return label\n",
    "\n",
    "def accuracy(theta):\n",
    "    return np.sum(predict(X_test, theta) == y_test)/X_test.shape[0]\n",
    "\n",
    "# L2 Clipping\n",
    "def L2_clip(v, b):\n",
    "    norm = np.linalg.norm(v, ord=2)\n",
    "    \n",
    "    if norm > b:\n",
    "        return b * (v / norm)\n",
    "    else:\n",
    "        return v\n",
    "\n",
    "def gradient_sum(theta, X, y, b):\n",
    "    gradients = [L2_clip(gradient(theta, x_i, y_i), b) for x_i, y_i in zip(X,y)]\n",
    "        \n",
    "    # sum query\n",
    "    # L2 sensitivity is b (by clipping performed above)\n",
    "    return np.sum(gradients, axis=0)\n",
    "    \n",
    "# Noisy gradient descent\n",
    "# Satisfies (k*epsilon + epsilon, k*delta)-differential privacy\n",
    "def noisy_gradient_descent(iterations, epsilon, delta):\n",
    "    theta = np.zeros(X_train.shape[1])\n",
    "    b = 3\n",
    "\n",
    "    noisy_count = laplace_mech(X_train.shape[0], 1, epsilon)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        clipped_gradient_sum = gradient_sum(theta, X_train, y_train, b)\n",
    "        noisy_gradient_sum = np.array(gaussian_mech_vec(clipped_gradient_sum, b, epsilon, delta))\n",
    "        noisy_avg_gradient = noisy_gradient_sum / noisy_count\n",
    "        theta = theta - noisy_avg_gradient\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (20 points)\n",
    "\n",
    "Implement `noisy_gradient_descent_RDP`, a variant of noisy gradient descent that uses RÃ©nyi differential privacy. Your solution should have a **total** privacy cost of $(\\alpha, \\bar\\epsilon)$-RDP.\n",
    "\n",
    "See [Chapter 8](https://uvm-plaid.github.io/programming-dp/notebooks/ch8.html#renyi-differential-privacy) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-226ebaadc7eca7a7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.7796329057938965\n"
     ]
    }
   ],
   "source": [
    "def gaussian_mech_RDP_vec(vec, sensitivity, alpha, epsilon):\n",
    "    sigma = np.sqrt((sensitivity**2 * alpha) / (2 * epsilon))\n",
    "    print(\"Sigma\", sigma)\n",
    "    return [v + np.random.normal(loc=0, scale=sigma) for v in vec]\n",
    "\n",
    "def noisy_gradient_descent_RDP(iterations, alpha, epsilon_bar):\n",
    "    ### BEGIN SOLUTION\n",
    "    theta = np.zeros(X_train.shape[1])\n",
    "    b = 3\n",
    "    epsilon_bar_count = 0.05 * epsilon_bar\n",
    "    epsilon_bar_i = 0.95 * epsilon_bar / iterations\n",
    "    \n",
    "    noisy_count = gaussian_mech_RDP_vec([len(X_train)], 1, alpha, epsilon_bar_count)[0]\n",
    "\n",
    "    for i in range(iterations):\n",
    "        clipped_gradient_sum = gradient_sum(theta, X_train, y_train, b)\n",
    "        noisy_gradient_sum = np.array(gaussian_mech_RDP_vec(clipped_gradient_sum, b, alpha, epsilon_bar_i))\n",
    "        noisy_avg_gradient = noisy_gradient_sum / noisy_count\n",
    "        theta = theta - noisy_avg_gradient\n",
    "\n",
    "    return theta\n",
    "    ### END SOLUTION\n",
    "\n",
    "theta = noisy_gradient_descent_RDP(10, 20, 0.1)\n",
    "print('Final accuracy:', accuracy(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-abdbebcaa40aa5f7",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE\n",
    "\n",
    "assert accuracy(noisy_gradient_descent_RDP(5, 100, 0.0001)) > 0.70\n",
    "assert accuracy(noisy_gradient_descent_RDP(5, 100, 0.00000001)) < 0.75\n",
    "assert accuracy(noisy_gradient_descent_RDP(5, 10000, 0.00001)) < 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (20 points)\n",
    "\n",
    "Implement `noisy_gradient_descent_zCDP`, a variant of noisy gradient descent that uses zero-concentrated differential privacy. Your solution should have a **total** privacy cost of $\\rho$-zCDP.\n",
    "\n",
    "See [Chapter 8](https://uvm-plaid.github.io/programming-dp/notebooks/ch8.html#zero-concentrated-differential-privacy) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4f06568475493433",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.7784166298098186\n"
     ]
    }
   ],
   "source": [
    "def gaussian_mech_zCDP_vec(vec, sensitivity, rho):\n",
    "    sigma = np.sqrt((sensitivity**2) / (2 * rho))\n",
    "    return [v + np.random.normal(loc=0, scale=sigma) for v in vec]\n",
    "\n",
    "def noisy_gradient_descent_zCDP(iterations, rho):\n",
    "    ### BEGIN SOLUTION\n",
    "    theta = np.zeros(X_train.shape[1])\n",
    "    b = 3\n",
    "    rho_count = 0.05 * rho\n",
    "    rho_i = 0.95 * rho / iterations\n",
    "  \n",
    "    noisy_count = gaussian_mech_zCDP_vec([len(X_train)], 1, rho_count)[0]\n",
    "\n",
    "    for i in range(iterations):\n",
    "        clipped_gradient_sum = gradient_sum(theta, X_train, y_train, b)\n",
    "        noisy_gradient_sum = np.array(gaussian_mech_zCDP_vec(clipped_gradient_sum, b, rho_i))\n",
    "        noisy_avg_gradient = noisy_gradient_sum / noisy_count\n",
    "        theta = theta - noisy_avg_gradient\n",
    "\n",
    "    return theta\n",
    "    ### END SOLUTION\n",
    "\n",
    "theta = noisy_gradient_descent_zCDP(10, 0.1)\n",
    "print('Final accuracy:', accuracy(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ccaeb1e7f69323a0",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE\n",
    "\n",
    "assert accuracy(noisy_gradient_descent_zCDP(5, 0.0000000001)) < 0.75\n",
    "assert accuracy(noisy_gradient_descent_zCDP(5, 0.0001)) > 0.70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (10 points)\n",
    "\n",
    "Which of the following functions is likely to produce the best accuracy for a given privacy cost, and why? Which is likely to produce the worst accuracy for a given privacy cost, and why?\n",
    "\n",
    "- `noisy_gradient_descent`\n",
    "- `noisy_gradient_descent_RDP`\n",
    "- `noisy_gradient_descent_zCDP`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ad66d2db62678537",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The RDP and zCDP variants will be the best, because they have better composition for the Gaussian mechanism. `noisy_gradient_descent` will be the worst, because it has looser composition. RDP and zCDP will be the same if $\\alpha$ is picked carefully for the RDP version, but zCDP might be better if $\\alpha$ is picked badly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (20 points)\n",
    "\n",
    "Implement `noisy_gradient_descent_zCDP_ED`, which has a **total privacy cost** of $(\\epsilon, \\delta)$-differential privacy, but which uses **zero-concentrated differential privacy** to perform composition.\n",
    "\n",
    "*Hint*: One approach is to:\n",
    "1. Convert $\\epsilon$ and $\\delta$ into an equivalent $\\rho$ parameter for zCDP\n",
    "2. Call `noisy_gradient_descent_zCDP` with the $\\rho$ from (1)\n",
    "\n",
    "See [Chapter 8](https://uvm-plaid.github.io/programming-dp/notebooks/ch8.html#zero-concentrated-differential-privacy) for more information on converting between variants.\n",
    "\n",
    "Note that you will need to *approximate $\\rho$ computationally*. In other words, there is no simple mathematical expression to calculate $\\rho$ based on $\\epsilon$ and $\\delta$; instead, you will want to:\n",
    "\n",
    "1. *Guess* a value for $\\rho$\n",
    "2. Calculate the corresponding $\\epsilon$ given $\\delta$\n",
    "3. If $\\epsilon$ is larger than the target, decrease the guess for $\\rho$. If $\\epsilon$ is smaller than the target, increase the guess for $\\rho$.\n",
    "4. Repeat these steps until you find a value for $\\rho$ that yields a close approximation of the target for $\\epsilon$, but does not exceed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-22c62835056276a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.7791906236178682\n"
     ]
    }
   ],
   "source": [
    "def noisy_gradient_descent_zCDP_ED(iterations, epsilon, delta):\n",
    "    ### BEGIN SOLUTION\n",
    "    def convert_rho(rho):\n",
    "        return rho + 2*np.sqrt(rho * np.log(1/delta))\n",
    "\n",
    "    rhos = np.linspace(0, 0.1, 100000)\n",
    "\n",
    "    last_rho = None\n",
    "    last_eps = None\n",
    "    for rho in rhos:\n",
    "        eps = convert_rho(rho)\n",
    "        if eps > epsilon:\n",
    "            break\n",
    "        else:\n",
    "            last_rho = rho\n",
    "            last_eps = eps\n",
    "    \n",
    "#     print(\"rho:\", last_rho)\n",
    "#     print(\"eps:\", last_eps)\n",
    "    return noisy_gradient_descent_zCDP(iterations, last_rho)\n",
    "    ### END SOLUTION\n",
    "\n",
    "theta = noisy_gradient_descent_zCDP_ED(10, 1.0, 1e-5)\n",
    "print('Final accuracy:', accuracy(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-26fab81b5bff9fc2",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CASE\n",
    "\n",
    "assert accuracy(noisy_gradient_descent_zCDP_ED(5, 0.1, 1e-5)) > 0.70\n",
    "assert accuracy(noisy_gradient_descent_zCDP_ED(5, 1.0, 1e-5)) > 0.70"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
